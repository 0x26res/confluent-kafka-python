# Use the latest 2.1 version of CircleCI pipeline process engine.
# See: https://circleci.com/docs/2.0/configuration-reference
version: 2.1

# Orbs are reusable packages of CircleCI configuration that you may share across projects, enabling you to create encapsulated, parameterized commands, jobs, and executors that can be used across multiple projects.
# See: https://circleci.com/docs/2.0/orb-intro/
orbs:
  # The python orb contains a set of prepackaged CircleCI configuration you can use repeatedly in your configuration files
  # Orb commands and jobs help you with common scripting around a language/tool
  # so you dont have to copy and paste it everywhere.
  # See the orb documentation here: https://circleci.com/developer/orbs/orb/circleci/python
  python: circleci/python@1.2

# Define a job to be invoked later in a workflow.
# See: https://circleci.com/docs/2.0/configuration-reference/#jobs
jobs:
  build-and-test: # This is the name of the job, feel free to change it to better match what you're trying to do!
    parameters:
      librdkafka_version:
        type: string
        default: v1.8.2
    # These next lines defines a Docker executors: https://circleci.com/docs/2.0/executor-types/
    # You can specify an image from Dockerhub or use one of the convenience images from CircleCI's Developer Hub
    # A list of available CircleCI Docker convenience images are available here: https://circleci.com/developer/images/image/cimg/python
    # The executor is the environment in which the steps below will be executed - below will use a python 3.8 container
    # Change the version below to your required version of python
    docker:
      - image: cimg/python:3.8
    # Checkout the code as the first step. This is a dedicated CircleCI step.
    # The python orb's install-packages step will install the dependencies from a Pipfile via Pipenv by default.
    # Here we're making sure we use just use the system-wide pip. By default it uses the project root's requirements.txt.
    # Then run your tests!
    # CircleCI will report the results back to your VCS provider.
    environment:
      LD_LIBRARY_PATH: ~/destdir/lib
    steps:
      - run:
         name: Print envs
         command: env | grep LD_LIBRARY
      - checkout
      - restore_cache:
          keys:
            - v1-librdkafka-builddir-<<parameters.librdkafka_version>>
      - run:
          name: Install interceptors
          command: tools/install-interceptors.sh
      - run:
          name: Install librdkafka
          command: tools/bootstrap-librdkafka.sh --require-ssl <<parameters.librdkafka_version>> destdir librdkafka-<<parameters.librdkafka_version>>
      - save_cache:
          key: v1-librdkafka-builddir-<<parameters.librdkafka_version>>
          paths:
            - librdkafka-<<parameters.librdkafka_version>>
      - python/install-packages:
          pkg-manager: pip
          # app-dir: ~/project/package-directory/  # If you're requirements.txt isn't in the root directory.
          pip-dependency-file: tests/requirements.txt
      - run:
          name: Install protobuf
          command: pip install -U protobuf
      - run:
          name: Build
          command: pip install --global-option=build_ext --global-option="-Idestdir/include/" --global-option="-Ldestdir/lib" . .[avro] .[schema-registry] .[json] .[protobuf]
      - run:
          name: Show linker info
          command: LD_LIBRARY_PATH=$LD_LIBRARY_PATH:destdir/lib ldd staging/libs/* || otool -L staging/libs/* || true
      - setup_remote_docker:
          version: 19.03.13
      - run:
          name: Run tests
          # FIXME: Skip integration tests for now as Docker networking is a bit of an issue with trivup
          #  TODO: Look into port-forwarding in trivup&docker.
          command: LD_LIBRARY_PATH=$LD_LIBRARY_PATH:destdir/lib:staging/libs DYLD_LIBRARY_PATH=$DYLD_LIBRARY_PATH:staging/libs python -m pytest --timeout 600 --ignore=destdir --ignore=tests/integration --junitxml=test-results/junit.xml
      - store_test_results:
          path: tests-results
      - run:
          name: Build wheel
          command: tools/wheels/build-wheels.sh <<parameters.librdkafka_version>> wheelhouse
      - store_artifacts:
          path: wheelhouse

# Invoke jobs via workflows
# See: https://circleci.com/docs/2.0/configuration-reference/#workflows
workflows:
  sample: # This is the name of the workflow, feel free to change it to better match your workflow.
    # Inside the workflow, you define the jobs you want to run.
    jobs:
      - build-and-test
